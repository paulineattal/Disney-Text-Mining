{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Méthode 1 : Récupérer champ par champ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 75\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m check \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     73\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m11\u001b[39m):\n\u001b[1;32m---> 75\u001b[0m         time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)      \n\u001b[0;32m     76\u001b[0m         \u001b[39mif\u001b[39;00m check \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m :\n\u001b[0;32m     77\u001b[0m             \u001b[39m# Nom voyageur\u001b[39;00m\n\u001b[0;32m     78\u001b[0m             name_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m//*[@id=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreview_list_page_container\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]/ul/li[\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m]/div/div[2]/div[1]/div[1]/div/div[2]/span[1]\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get the driver\n",
    "\n",
    "HotelsUrls = {'Newport_Bay_Club' : 'https://www.booking.com/hotel/fr/disney-39-s-newport-bay-club-r.fr.html#tab-reviews', 'Cheyenne' : 'https://www.booking.com/hotel/fr/disney-39-s-cheyenne-r.fr.html#tab-reviews', 'Sequoia_Lodge' : 'https://www.booking.com/hotel/fr/disneys-sequoia-lodge-r.fr.html#tab-reviews', 'New_York' : 'https://www.booking.com/hotel/fr/disney-39-s-new-york-r.fr.html#tab-reviews', 'Davy_Crockett_Ranch' : 'https://www.booking.com/hotel/fr/disneys-davy-crockett-ranch.fr.html#tab-reviews', 'Santa_Fe' : 'https://www.booking.com/hotel/fr/disney-39-s-santa-fe-r.fr.html#tab-reviews'}\n",
    "\n",
    "chiffres = list(\"0123456789\")\n",
    "\n",
    "for hotel in range(len(HotelsUrls)) : \n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "    driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "    # Create list to get the data\n",
    "    collectName = []\n",
    "    collectCountry = []\n",
    "    collectType_room = []\n",
    "    collectLen_reservation = []\n",
    "    collectMonth_year = []\n",
    "    collectVoyageur_info = []\n",
    "    collectDate_review = []\n",
    "    collectReview_title = []\n",
    "    collectGrade_review = []\n",
    "    collectPositive_review = []\n",
    "    collectNegative_review = []\n",
    "    collectIs_review_usefull = []\n",
    "    collectUniqueID = []\n",
    "\n",
    "    git = 'https://github.com/paulineattal/Disney-Text-Mining/BDD/CSV/Scrapping_' + str(list(HotelsUrls.keys())[hotel]) + '.csv'\n",
    "    link = git.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\")\n",
    "    try : \n",
    "        checkUrl = requests.get(link).content\n",
    "        checkScrapping = pd.read_csv(io.StringIO(checkUrl.decode('utf-8')), sep = ';')\n",
    "    except : \n",
    "        pass \n",
    "\n",
    "    url = HotelsUrls.get(list(HotelsUrls.keys())[hotel])\n",
    "\n",
    "    # Put the url into the driver\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)\n",
    "    # Reject cookies\n",
    "    driver.find_element(By.ID, \"onetrust-reject-all-handler\").click()\n",
    "\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"review_sort\"]/option[2]').click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    driver.find_element(By.CLASS_NAME, \"pagenext\").click()     \n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "    n_pages = int(driver.find_element(By.XPATH, '//*[@id=\"review_list_page_container\"]/div[4]/div/div[1]/div/div[2]/div/div[7]/a/span[1]').text)\n",
    "\n",
    "    check = 0\n",
    "\n",
    "    for p in range(1,n_pages+1):\n",
    "        time.sleep(2)\n",
    "\n",
    "        if check == 0:\n",
    "\n",
    "            for i in range(1,11):\n",
    "                \n",
    "                time.sleep(1)      \n",
    "                if check == 0 :\n",
    "                    # Nom voyageur\n",
    "                    name_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[1]/div/div[2]/span[1]'\n",
    "                    try:\n",
    "                        name = driver.find_element(By.XPATH, name_path).text\n",
    "                    except:\n",
    "                        name = np.nan\n",
    "                    collectName.append(name)\n",
    "\n",
    "                    # Pays voyageur\n",
    "                    country_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[1]/div/div[2]/span[2]'\n",
    "                    try:\n",
    "                        country = driver.find_element(By.XPATH, country_path).text\n",
    "                    except:\n",
    "                        country = np.nan\n",
    "                    collectCountry.append(country)\n",
    "\n",
    "                    # Type de chambre\n",
    "                    type_room_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[2]/ul/li/a'\n",
    "        \n",
    "                    try: \n",
    "                        type_room = driver.find_element(By.XPATH, type_room_path).text\n",
    "                    except:\n",
    "                        type_room = np.nan\n",
    "                    collectType_room.append(type_room)\n",
    "\n",
    "                    # Nuitées\n",
    "                    len_reservation_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[1]/li/div'\n",
    "                    try:\n",
    "                        len_reservation = driver.find_element(By.XPATH, len_reservation_path).text\n",
    "                    except:\n",
    "                        len_reservation = \"N\"\n",
    "                    collectLen_reservation.append(len_reservation)\n",
    "\n",
    "                    # Mois année du voyage\n",
    "                    month_year_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[1]/li/div/span'\n",
    "                    try:\n",
    "                        month_year = driver.find_element(By.XPATH, month_year_path).text\n",
    "                    except:\n",
    "                        month_year = np.nan\n",
    "                    collectMonth_year.append(month_year)\n",
    "\n",
    "                    # Informations voyageur\n",
    "                    voyageur_info_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[2]/li'\n",
    "                    try:\n",
    "                        voyageur_info = driver.find_element(By.XPATH, voyageur_info_path).text\n",
    "                    except:\n",
    "                        voyageur_info = np.nan\n",
    "                    collectVoyageur_info.append(voyageur_info)\n",
    "\n",
    "                    # Date \n",
    "                    date_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/span'\n",
    "                    date_review_path2 = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/span[2]'\n",
    "\n",
    "                    try:\n",
    "                        date_review = driver.find_element(By.XPATH, date_review_path).text\n",
    "                    except:\n",
    "                        date_review = np.nan\n",
    "\n",
    "                    if date_review == 'Le choix des voyageurs' : \n",
    "        \n",
    "                        try:\n",
    "                            date_review = driver.find_element(By.XPATH, date_review_path2).text\n",
    "                        except:\n",
    "                            date_review = np.nan\n",
    "                    collectDate_review.append(date_review)\n",
    "\n",
    "                    # Titre commentaire \n",
    "                    review_title_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/div/div[1]/h3'\n",
    "                    try:\n",
    "                        review_title = driver.find_element(By.XPATH, review_title_path).text\n",
    "                    except:\n",
    "                        review_title = np.nan\n",
    "                    collectReview_title.append(review_title)\n",
    "        \n",
    "                    # Note\n",
    "                    grade_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/div/div[2]/div/div'\n",
    "                    try:\n",
    "                        grade_review = driver.find_element(By.XPATH, grade_review_path).text\n",
    "                    except:\n",
    "                        grade_review = np.nan\n",
    "                    collectGrade_review.append(grade_review)\n",
    "\n",
    "                    # Commentaire positif\n",
    "                    positive_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[2]/div/div[1]/p/span[3]'\n",
    "                    try:\n",
    "                        positive_review = driver.find_element(By.XPATH, positive_review_path).text\n",
    "                    except: \n",
    "                        positive_review = np.nan\n",
    "                    collectPositive_review.append(positive_review)\n",
    "        \n",
    "                    # Commentaire négatif\n",
    "                    negative_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[2]/div/div[2]/p/span[3]'\n",
    "                    try:\n",
    "                        negative_review = driver.find_element(By.XPATH, negative_review_path).text\n",
    "                    except:\n",
    "                        negative_review = np.nan\n",
    "                    collectNegative_review.append(negative_review)\n",
    "\n",
    "                    # Utilité commentaire\n",
    "                    is_review_usefull_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[3]/div/div[1]'\n",
    "                    try:\n",
    "                        is_review_usefull = driver.find_element(By.XPATH, is_review_usefull_path).text\n",
    "                    except:\n",
    "                        is_review_usefull = np.nan\n",
    "                    collectIs_review_usefull.append(is_review_usefull)\n",
    "\n",
    "                    UniqueID = str(name) + str(country) + str(type_room) + str(month_year) + str(voyageur_info) + str(date_review) + str(review_title)\n",
    "                    \n",
    "                    try: \n",
    "                        check = len(checkScrapping[checkScrapping['UniqueID'] == UniqueID])\n",
    "                    except: \n",
    "                        check = 0\n",
    "                \n",
    "\n",
    "                    collectUniqueID.append(UniqueID)\n",
    "        \n",
    "            # Changer de page    \n",
    "            try:\n",
    "                driver.find_element(By.CLASS_NAME, \"pagenext\").click()     \n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    # Créer le dataframe\n",
    "    Names = collectName\n",
    "    Country = collectCountry\n",
    "    room_type = collectType_room\n",
    "    nuitee = collectLen_reservation\n",
    "    reservation_date = collectMonth_year\n",
    "    traveler_infos = collectVoyageur_info\n",
    "    date_review = collectDate_review\n",
    "    review_title = collectReview_title\n",
    "    grade_review = collectGrade_review\n",
    "    positive_review = collectPositive_review\n",
    "    negative_review = collectNegative_review\n",
    "    usefulness_review = collectIs_review_usefull\n",
    "    UniqueID = collectUniqueID\n",
    "    columns = ['Names', 'Country', 'room_type', 'nuitee', 'reservation_date', 'traveler_infos', 'date_review', 'review_title', 'grade_review', 'positive_review', 'negative_review', 'usefulness_review', 'UniqueID']\n",
    "    df = pd.DataFrame(list(zip(Names, Country,room_type, nuitee, reservation_date, traveler_infos, date_review, review_title, grade_review, positive_review, negative_review, usefulness_review, UniqueID)), columns=columns)\n",
    "    df=df.assign(hotel= str(list(HotelsUrls.keys())[hotel]))\n",
    "  \n",
    "    # Traitement de la ligne usefulness_review : Garder uniquement le nombre de fois que le commentaire a été trouvé utile\n",
    "    df.loc[(df.usefulness_review == 'Utile Pas utile'),'usefulness_review']= 'NaN'\n",
    "    df['usefulness_review'] = df['usefulness_review'].str[:2]\n",
    "\n",
    "    # Remplacer les cases ou il n'y a pas d'avis positif par 0\n",
    "    df.loc[df.usefulness_review == \"Na\", \"usefulness_review\"] = \"0\"\n",
    "    df.loc[pd.isna(df.usefulness_review), \"usefulness_review\"] = \"0\"\n",
    "\n",
    "    # Remplacer les nuitees non complétées par np.nan\n",
    "    df.loc[df.nuitee == \"N\", \"nuitee\"] = np.nan\n",
    "    # Garder uniquement le nombre de nuitee passée dans l'hotel\n",
    "    df[\"nuitee\"] = df[\"nuitee\"].str[:1]\n",
    "\n",
    "    if checkScrapping.columns[0] == '404: Not Found' : \n",
    "        pass\n",
    "    else: \n",
    "        df = pd.concat([df, checkScrapping], ignore_index=True)\n",
    "\n",
    "    # Supprimer les doublons (si jamais il en existe, normalement non)\n",
    "    df.drop_duplicates(keep='first')\n",
    "    # Supprimer les lignes qui ont été récupérées en trop\n",
    "    df.drop(df[df['UniqueID'] == 'nannannannannannannan'].index, inplace = True)\n",
    "\n",
    "    # Enregistrer le fichier\n",
    "    df.to_csv(r'C:\\Users\\houde\\Desktop\\Scrapping\\Scrapping_' + str(list(HotelsUrls.keys())[hotel]) + '.csv', index = False, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names = collectName\n",
    "Country = collectCountry\n",
    "room_type = collectType_room\n",
    "nuitee = collectLen_reservation\n",
    "reservation_date = collectMonth_year\n",
    "traveler_infos = collectVoyageur_info\n",
    "date_review = collectDate_review\n",
    "review_title = collectReview_title\n",
    "grade_review = collectGrade_review\n",
    "positive_review = collectPositive_review\n",
    "negative_review = collectNegative_review\n",
    "usefulness_review = collectIs_review_usefull\n",
    "UniqueID = collectUniqueID\n",
    "columns = ['Names', 'Country', 'room_type', 'nuitee', 'reservation_date', 'traveler_infos', 'date_review', 'review_title', 'grade_review', 'positive_review', 'negative_review', 'usefulness_review', 'UniqueID']\n",
    "\n",
    "df = pd.DataFrame(list(zip(Names, Country,room_type, nuitee, reservation_date, traveler_infos, date_review, review_title, grade_review, positive_review, negative_review, usefulness_review, UniqueID)), columns=columns)\n",
    "#df=df.assign(hotel= str(list(HotelsUrls.keys())[i]))\n",
    "\n",
    "df.loc[(df.usefulness_review == 'Utile Pas utile'),'usefulness_review']='NaN'\n",
    "\n",
    "df['usefulness_review'] = df['usefulness_review'].str[:2]\n",
    "\n",
    "for i in range(len(df)): \n",
    "\n",
    "    if df['usefulness_review'][i] == \"em\":\n",
    "        df['usefulness_review'][i] = 0\n",
    "\n",
    "    if df['usefulness_review'][i] is None:\n",
    "        df['usefulness_review'][i] = 0\n",
    "\n",
    "    if df['usefulness_review'][i] is \"Na\":\n",
    "        df['usefulness_review'][i] = 0\n",
    "\n",
    "df.drop_duplicates(keep='first')\n",
    "\n",
    "df.to_csv(r'C:\\Users\\houde\\Documents\\GitHub\\Disney-Text-Mining\\fichiers\\Scrapping_' + str(list(HotelsUrls.keys())[i]) + '.csv', index = False, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\houde\\Documents\\GitHub\\Disney-Text-Mining\\Scrapping\\Scrapping_Newport_Bay_Club\n"
     ]
    }
   ],
   "source": [
    "HotelsUrls = {'Newport_Bay_Club' : 'https://www.booking.com/hotel/fr/disney-39-s-newport-bay-club-r.fr.html#tab-reviews', 'Cheyenne' : 'https://www.booking.com/hotel/fr/disney-39-s-cheyenne-r.fr.html#tab-reviews', 'Sequoia_Lodge' : 'https://www.booking.com/hotel/fr/disneys-sequoia-lodge-r.fr.html#tab-reviews', 'New_York' : 'https://www.booking.com/hotel/fr/disney-39-s-new-york-r.fr.html#tab-reviews', 'Davy_Crockett_Ranch' : 'https://www.booking.com/hotel/fr/disneys-davy-crockett-ranch.fr.html#tab-reviews', 'Santa_Fe' : 'https://www.booking.com/hotel/fr/disney-39-s-santa-fe-r.fr.html#tab-reviews'}\n",
    "\n",
    "print(r'C:\\Users\\houde\\Documents\\GitHub\\Disney-Text-Mining\\Scrapping\\Scrapping_' + str(list(HotelsUrls.keys())[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\houde\\AppData\\Local\\Temp\\ipykernel_19532\\2141512684.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get the driver\n",
    "\n",
    "HotelsUrls = {'Newport_Bay_Club' : 'https://www.booking.com/hotel/fr/disney-39-s-newport-bay-club-r.fr.html#tab-reviews', 'Cheyenne' : 'https://www.booking.com/hotel/fr/disney-39-s-cheyenne-r.fr.html#tab-reviews', 'Sequoia_Lodge' : 'https://www.booking.com/hotel/fr/disneys-sequoia-lodge-r.fr.html#tab-reviews', 'New_York' : 'https://www.booking.com/hotel/fr/disney-39-s-new-york-r.fr.html#tab-reviews', 'Davy_Crockett_Ranch' : 'https://www.booking.com/hotel/fr/disneys-davy-crockett-ranch.fr.html#tab-reviews', 'Santa_Fe' : 'https://www.booking.com/hotel/fr/disney-39-s-santa-fe-r.fr.html#tab-reviews'}\n",
    "\n",
    "chiffres = list(\"0123456789\")\n",
    "\n",
    "for hotel in range(len(HotelsUrls)) : \n",
    "\n",
    "    driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n",
    "\n",
    "    # Create list to get the data\n",
    "    collectName = []\n",
    "    collectCountry = []\n",
    "    collectType_room = []\n",
    "    collectLen_reservation = []\n",
    "    collectMonth_year = []\n",
    "    collectVoyageur_info = []\n",
    "    collectDate_review = []\n",
    "    collectReview_title = []\n",
    "    collectGrade_review = []\n",
    "    collectPositive_review = []\n",
    "    collectNegative_review = []\n",
    "    collectIs_review_usefull = []\n",
    "    collectUniqueID = []\n",
    "\n",
    "    git = 'https://github.com/paulineattal/Disney-Text-Mining/blob/main/fichiers/Scrapping_' + str(list(HotelsUrls.keys())[hotel]) + '.csv'\n",
    "    link = git.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\")\n",
    "    try : \n",
    "        checkUrl = requests.get(link).content\n",
    "        checkScrapping = pd.read_csv(io.StringIO(checkUrl.decode('utf-8')), sep = ';')\n",
    "    except : \n",
    "        pass \n",
    "\n",
    "    url = HotelsUrls.get(list(HotelsUrls.keys())[hotel])\n",
    "\n",
    "    # Put the url into the driver\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)\n",
    "    # Reject cookies\n",
    "    driver.find_element(By.ID, \"onetrust-reject-all-handler\").click()\n",
    "\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"review_sort\"]/option[2]').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    n_pages = driver.find_element(By.XPATH, '//*[@id=\"review_list_page_container\"]/div[4]/div/div[1]/div/div[2]/div/div[7]/a/span[1]').text\n",
    "    n_pages = int(n_pages)\n",
    "\n",
    "    check = 0\n",
    "\n",
    "    for p in range(1,n_pages+1):\n",
    "        time.sleep(2)\n",
    "\n",
    "        if check == 0:\n",
    "\n",
    "            for i in range(1,11):\n",
    "                \n",
    "                time.sleep(1)      \n",
    "                if check == 0 :\n",
    "                    # Nom voyageur\n",
    "                    name_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[1]/div/div[2]/span[1]'\n",
    "                    try:\n",
    "                        name = driver.find_element(By.XPATH, name_path).text\n",
    "                    except:\n",
    "                        name = np.nan\n",
    "                    collectName.append(name)\n",
    "\n",
    "                    # Pays voyageur\n",
    "                    country_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[1]/div/div[2]/span[2]'\n",
    "                    try:\n",
    "                        country = driver.find_element(By.XPATH, country_path).text\n",
    "                    except:\n",
    "                        country = np.nan\n",
    "                    collectCountry.append(country)\n",
    "\n",
    "                    # Type de chambre\n",
    "                    type_room_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[2]/ul/li/a'\n",
    "        \n",
    "                    try: \n",
    "                        type_room = driver.find_element(By.XPATH, type_room_path).text\n",
    "                    except:\n",
    "                        type_room = np.nan\n",
    "                    collectType_room.append(type_room)\n",
    "\n",
    "                    # Nuitées\n",
    "                    len_reservation_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[1]/li/div'\n",
    "                    try:\n",
    "                        len_reservation = driver.find_element(By.XPATH, len_reservation_path).text\n",
    "                    except:\n",
    "                        len_reservation = np.nan\n",
    "                    collectLen_reservation.append(len_reservation[0])\n",
    "\n",
    "                    # Mois année du voyage\n",
    "                    month_year_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[1]/li/div/span'\n",
    "                    try:\n",
    "                        month_year = driver.find_element(By.XPATH, month_year_path).text\n",
    "                    except:\n",
    "                        month_year = np.nan\n",
    "                    collectMonth_year.append(month_year)\n",
    "\n",
    "                    # Informations voyageur\n",
    "                    voyageur_info_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[2]/li'\n",
    "                    try:\n",
    "                        voyageur_info = driver.find_element(By.XPATH, voyageur_info_path).text\n",
    "                    except:\n",
    "                        voyageur_info = np.nan\n",
    "                    collectVoyageur_info.append(voyageur_info)\n",
    "\n",
    "                    # Date \n",
    "                    date_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/span'\n",
    "                    date_review_path2 = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/span[2]'\n",
    "\n",
    "                    try:\n",
    "                        date_review = driver.find_element(By.XPATH, date_review_path).text\n",
    "                    except:\n",
    "                        date_review = np.nan\n",
    "\n",
    "                    if date_review == 'Le choix des voyageurs' : \n",
    "        \n",
    "                        try:\n",
    "                            date_review = driver.find_element(By.XPATH, date_review_path2).text\n",
    "                        except:\n",
    "                            date_review = np.nan\n",
    "                    collectDate_review.append(date_review)\n",
    "\n",
    "                    # Titre commentaire \n",
    "                    review_title_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/div/div[1]/h3'\n",
    "                    try:\n",
    "                        review_title = driver.find_element(By.XPATH, review_title_path).text\n",
    "                    except:\n",
    "                        review_title = np.nan\n",
    "                    collectReview_title.append(review_title)\n",
    "        \n",
    "                    # Note\n",
    "                    grade_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/div/div[2]/div/div'\n",
    "                    try:\n",
    "                        grade_review = driver.find_element(By.XPATH, grade_review_path).text\n",
    "                    except:\n",
    "                        grade_review = np.nan\n",
    "                    collectGrade_review.append(grade_review)\n",
    "\n",
    "                    # Commentaire positif\n",
    "                    positive_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[2]/div/div[1]/p/span[3]'\n",
    "                    try:\n",
    "                        positive_review = driver.find_element(By.XPATH, positive_review_path).text\n",
    "                    except: \n",
    "                        positive_review = np.nan\n",
    "                    collectPositive_review.append(positive_review)\n",
    "        \n",
    "                    # Commentaire négatif\n",
    "                    negative_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[2]/div/div[2]/p/span[3]'\n",
    "                    try:\n",
    "                        negative_review = driver.find_element(By.XPATH, negative_review_path).text\n",
    "                    except:\n",
    "                        negative_review = np.nan\n",
    "                    collectNegative_review.append(negative_review)\n",
    "\n",
    "                    # Utilité commentaire\n",
    "                    is_review_usefull_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[3]/div/div[1]'\n",
    "                    try:\n",
    "                        is_review_usefull = driver.find_element(By.XPATH, is_review_usefull_path).text\n",
    "                    except:\n",
    "                        is_review_usefull = np.nan\n",
    "                    collectIs_review_usefull.append(is_review_usefull)\n",
    "\n",
    "                    UniqueID = str(name) + str(country) + str(type_room) + str(month_year) + str(voyageur_info) + str(date_review) + str(review_title)\n",
    "                    \n",
    "                    try: \n",
    "                        check = len(checkScrapping[checkScrapping['UniqueID'] == UniqueID])\n",
    "                    except: \n",
    "                        check = 0\n",
    "                \n",
    "\n",
    "                    collectUniqueID.append(UniqueID)\n",
    "        \n",
    "            # Changer de page    \n",
    "            try:\n",
    "                driver.find_element(By.CLASS_NAME, \"pagenext\").click()     \n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    # Créer le dataframe\n",
    "    Names = collectName\n",
    "    Country = collectCountry\n",
    "    room_type = collectType_room\n",
    "    nuitee = collectLen_reservation\n",
    "    reservation_date = collectMonth_year\n",
    "    traveler_infos = collectVoyageur_info\n",
    "    date_review = collectDate_review\n",
    "    review_title = collectReview_title\n",
    "    grade_review = collectGrade_review\n",
    "    positive_review = collectPositive_review\n",
    "    negative_review = collectNegative_review\n",
    "    usefulness_review = collectIs_review_usefull\n",
    "    UniqueID = collectUniqueID\n",
    "    columns = ['Names', 'Country', 'room_type', 'nuitee', 'reservation_date', 'traveler_infos', 'date_review', 'review_title', 'grade_review', 'positive_review', 'negative_review', 'usefulness_review', 'UniqueID']\n",
    "    df = pd.DataFrame(list(zip(Names, Country,room_type, nuitee, reservation_date, traveler_infos, date_review, review_title, grade_review, positive_review, negative_review, usefulness_review, UniqueID)), columns=columns)\n",
    "    df=df.assign(hotel= str(list(HotelsUrls.keys())[hotel]))\n",
    "\n",
    "    # Traitement de la ligne usefulness_review : Garder uniquement le nombre de fois que le commentaire a été trouvé utile\n",
    "    df.loc[(df.usefulness_review == 'Utile Pas utile'),'usefulness_review']= 'NaN'\n",
    "    df['usefulness_review'] = df['usefulness_review'].str[:2]\n",
    "\n",
    "    for i in range(len(df)): \n",
    "\n",
    "        if df['usefulness_review'][i] == \"Na\" or pd.isna(df['usefulness_review'][i]) :\n",
    "            df['usefulness_review'][i] = \"0\"\n",
    "    \n",
    "    # Garder uniquement le nombre de nuitee passée dans l'hotel\n",
    "    df[\"nuitee\"] = df[\"nuitee\"].str[:1]\n",
    "\n",
    "    if checkScrapping.columns[0] == '404: Not Found' : \n",
    "        pass\n",
    "    else: \n",
    "        df = pd.concat([df, checkScrapping], ignore_index=True)\n",
    "\n",
    "    # Supprimer les doublons (si jamais il en existe, normalement non)\n",
    "    df.drop_duplicates(keep='first')\n",
    "    # Supprimer les lignes qui ont été récupérées en trop\n",
    "    df.drop(df[df['UniqueID'] == 'emptyemptyemptyemptyemptyemptyempty'].index, inplace = True)\n",
    "\n",
    "    # Enregistrer le fichier à mettre\n",
    "    df.to_csv(r'C:\\Users\\houde\\Documents\\GitHub\\Disney-Text-Mining\\fichiers\\Scrapping_' + str(list(HotelsUrls.keys())[hotel]) + '.csv', index = False, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Names      Country                                    room_type  \\\n",
      "0        Adamik       Suisse  Chambre Club Compass - Côté Lac (2 Adultes)   \n",
      "1      Caroline       France                           Chambre Supérieure   \n",
      "2            Yi       Taïwan                           Chambre Supérieure   \n",
      "3       Antoine       France                           Chambre Supérieure   \n",
      "4       Jensmkl    Allemagne                           Chambre Supérieure   \n",
      "...         ...          ...                                          ...   \n",
      "1177  Katherine  Royaume-Uni                        Chambre Standard Cars   \n",
      "1178     Ilenia       Italie    Chambre Standard Cars - Proche Commodités   \n",
      "1179     Hiromi     Belgique                        Chambre Standard Cars   \n",
      "1180    Leblanc     Belgique         Chambre Standard Cars - Côté Rivière   \n",
      "1181    Anonyme     Pays-Bas                                          NaN   \n",
      "\n",
      "      nuitee reservation_date traveler_infos  \\\n",
      "0        1.0     Janvier 2023         Couple   \n",
      "1        1.0     Janvier 2023        Famille   \n",
      "2        1.0     Janvier 2023        Famille   \n",
      "3        1.0     Janvier 2023         Groupe   \n",
      "4        1.0     Janvier 2023         Couple   \n",
      "...      ...              ...            ...   \n",
      "1177     3.0    Novembre 2022        Famille   \n",
      "1178     1.0     Janvier 2023        Famille   \n",
      "1179     1.0    Novembre 2022        Famille   \n",
      "1180     1.0     Janvier 2023        Famille   \n",
      "1181     1.0     Janvier 2023         Couple   \n",
      "\n",
      "                                date_review  \\\n",
      "0      Commentaire envoyé le 1 février 2023   \n",
      "1     Commentaire envoyé le 31 janvier 2023   \n",
      "2     Commentaire envoyé le 31 janvier 2023   \n",
      "3     Commentaire envoyé le 31 janvier 2023   \n",
      "4     Commentaire envoyé le 30 janvier 2023   \n",
      "...                                     ...   \n",
      "1177   Commentaire envoyé le 4 janvier 2023   \n",
      "1178   Commentaire envoyé le 4 janvier 2023   \n",
      "1179   Commentaire envoyé le 4 janvier 2023   \n",
      "1180   Commentaire envoyé le 4 janvier 2023   \n",
      "1181   Commentaire envoyé le 3 janvier 2023   \n",
      "\n",
      "                                           review_title grade_review  \\\n",
      "0                                          Exceptionnel           10   \n",
      "1                                          Exceptionnel           10   \n",
      "2                                              Passable          5,0   \n",
      "3                                              Passable          5,0   \n",
      "4                                       Urlaub zu Zweit          8,0   \n",
      "...                                                 ...          ...   \n",
      "1177  loved our trip to Disney Santa Fe was perfect ...          7,0   \n",
      "1178                                          Très bien          8,0   \n",
      "1179                                              Bien           7,0   \n",
      "1180                                            Mauvais          1,0   \n",
      "1181                                           Passable          5,0   \n",
      "\n",
      "                                        positive_review negative_review  \\\n",
      "0                                                   NaN             NaN   \n",
      "1                                                   NaN             NaN   \n",
      "2                                                   NaN             NaN   \n",
      "3                                                   NaN             NaN   \n",
      "4                                                   NaN             NaN   \n",
      "...                                                 ...             ...   \n",
      "1177                                                NaN             NaN   \n",
      "1178                                                NaN             NaN   \n",
      "1179                                                NaN             NaN   \n",
      "1180  Je ne serait pas vous dire car nous n'avons pa...             NaN   \n",
      "1181                                                NaN             NaN   \n",
      "\n",
      "      usefulness_review                                           UniqueID  \\\n",
      "0                     0  AdamikSuisseChambre Club Compass - Côté Lac (2...   \n",
      "1                     0  CarolineFranceChambre SupérieureJanvier 2023Fa...   \n",
      "2                     0  YiTaïwanChambre SupérieureJanvier 2023FamilleC...   \n",
      "3                     0  AntoineFranceChambre SupérieureJanvier 2023Gro...   \n",
      "4                     0  JensmklAllemagneChambre SupérieureJanvier 2023...   \n",
      "...                 ...                                                ...   \n",
      "1177                  0  KatherineRoyaume-UniChambre Standard CarsNovem...   \n",
      "1178                  0  IleniaItalieChambre Standard Cars - Proche Com...   \n",
      "1179                  0  HiromiBelgiqueChambre Standard CarsNovembre 20...   \n",
      "1180                  0  LeblancBelgiqueChambre Standard Cars - Côté Ri...   \n",
      "1181                  0  AnonymePays-BasnanJanvier 2023CoupleCommentair...   \n",
      "\n",
      "                 hotel  \n",
      "0     Newport_Bay_Club  \n",
      "1     Newport_Bay_Club  \n",
      "2     Newport_Bay_Club  \n",
      "3     Newport_Bay_Club  \n",
      "4     Newport_Bay_Club  \n",
      "...                ...  \n",
      "1177          Santa_Fe  \n",
      "1178          Santa_Fe  \n",
      "1179          Santa_Fe  \n",
      "1180          Santa_Fe  \n",
      "1181          Santa_Fe  \n",
      "\n",
      "[1182 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(r\"C:\\Users\\houde\\Documents\\GitHub\\Disney-Text-Mining\\BDD\\CSV\")\n",
    "\n",
    "df = pd.read_csv('update.csv', sep = \";\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdate\u001b[39m.\u001b[39mtoday()\n\u001b[0;32m      3\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39massign(execution_date\u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(date))\n\u001b[1;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpsycopg2\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mextras\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "date = datetime.date.today()\n",
    "df = df.assign(execution_date= str(date))\n",
    "\n",
    "import psycopg2\n",
    "import extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'psycopg2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLe dataframe à été inseré\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     cursor\u001b[39m.\u001b[39mclose()\n\u001b[1;32m---> 18\u001b[0m conn \u001b[39m=\u001b[39m psycopg2\u001b[39m.\u001b[39mconnect(\n\u001b[0;32m     19\u001b[0m             user \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mm140\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m             password \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mm140\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m             host \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdb-etu.univ-lyon2.fr\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m             port \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m5432\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m             database \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mm140\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     24\u001b[0m         )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'psycopg2' is not defined"
     ]
    }
   ],
   "source": [
    "def insert_values(conn, df, table):\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL query to execute\n",
    "    query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Erreur: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"Le dataframe à été inseré\")\n",
    "    cursor.close()\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "            user = \"m140\",\n",
    "            password = \"m140\",\n",
    "            host = \"db-etu.univ-lyon2.fr\",\n",
    "            port = \"5432\",\n",
    "            database = \"m140\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fct.insert_values(conn, df, 'history')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\houde\\Documents\\GitHub\\Disney-Text-Mining\\fichiers\")\n",
    "df = pd.read_csv(\"Scrapping_Sequoia_Lodge.csv\", sep = \";\")\n",
    "df[\"nuitee\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b16b5e40b26fc74d21e921d7f9348a7b0997adadfafa1fa5a2ce7e2f89b5982f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
